[
  {
    "title": "DiffSimViz",
    "goals": "DiffSimViz (Diffusion Simulator Visualizer) will be a python toolbox with the aim of providing intuitive visualizations of particle diffusion in different media/microstructure. This will ideally include an interface to choose particular media to visualize diffusion within, as well as to change parameters such as diffusion time and membrane permeability. The use of such a visualizer will be didactic, or for researchers to better understand what their diffusion MRI signal might look like in particular microstructural environments.",
    "link": "https://github.com/Bradley-Karat/DiffSimViz",
    "website-image": null,
    "project-leads": "Bradlet Karat, Github: @Bradley-Karat, Discord: brad_karat",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "- Python\n- Diffusion MRI\n- Visualization generation",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[Virtualization](https://school-brainhack.github.io/modules/containers/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "DiffSimViz",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/37",
    "issue_number": 37
  },
  {
    "title": "Simulation of the interplay between brain and behavior",
    "goals": "Multiple longitudinal studies of neurodevelopment are now emerging and are openly available (baby connectome, ABCD, etc.). However, it's unclear the best approaches to model data longitudinally, given that the gold standard is often unclear. Thus, the goal of this project is for several different groups to generate longitudinal simulated data with embedding aspects of typical and atypical brain development into the the code. Initially, the plan is that the data will be released and after approximately one year, the code with the data will be released. This will allow different groups to assess the code.",
    "link": "https://github.com/tonyajohansonwhite/LongSim",
    "website-image": null,
    "project-leads": "Tonya White\nGithub login: tonyajohansonwhite",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Brian development, coding, neuroimaging",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)"
    ],
    "issues": "all invited",
    "twiter": "not written yet.",
    "chatchannel": "LongSim",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/35",
    "issue_number": 35
  },
  {
    "title": "Solving the NIH's Underpants Problem with open bibliometrics and OpenAlex.",
    "goals": "We plan to build an open and transparent source resource where program officers can obtain information about data sharing statements for a given paper. The interface will provide aggregation by investigator,  institution, grant, etc. It will also provide mechanism for investigators to submit correction  (PRs)",
    "link": "https://tokyo.o18s.com/\nhttps://openalex.org/",
    "website-image": null,
    "project-leads": "Adam Thomas @agt24 Discord:adamtNIH",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "- Front end (java script)\n- containers\n- CI\n- Python\n- Github",
    "tutorials": [
      "[A introduction to Bash](https://school-brainhack.github.io/modules/introduction_to_terminal/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "sharestats",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/34",
    "issue_number": 34
  },
  {
    "title": "NeuroLibre reproducible preprints",
    "goals": "The NeuroLibre team led by Ag\u00e2h Karakuzu just released the beta version of [NeuroLibre](https://neurolibre.com).\nThis next-generation publication platform offers complete testing of preprints, including recreation of the computational and data environment, and reproduction of all figures, as part of the preprint publication process. All reproducibility assets are archived alongside a re-executable web version of the preprint upon acceptance.\nNeurolibre is based on github and the popular Jupyter book project, based on traditional or Myst notebooks.\nThe objective of this project is to assist people get started creating their first reproducible preprint. We hope that this brainhack can ignite the first wave of publication of truly reproducible science.",
    "link": "https://neurolibre.org",
    "website-image": "https://raw.githubusercontent.com/neurolibre/brand/main/png/card_tb.png",
    "project-leads": "Pierre Bellec @pbellec (both on github and on Discord)",
    "hub": "Montreal",
    "otherhub": [
      "Americas"
    ],
    "skills": "The ideal profile to start a NeuroLibre preprint is to have a work in preparation (or already published) which is supported by a collection of Jupyter Notebooks, and based on open data (at least partially).\nYou can learn all the rest as you go using our complete documentation: https://docs.neurolibre.org/en/latest/ and the support of our team during the hackathon.",
    "tutorials": [],
    "issues": null,
    "twiter": "The https://neurolibre.org/ reproducible preprint service is now open for beta! Published preprints are re-executable and include all the artefacts needed for reproduction (and it's been tested). Come work on your first NeuroLibre submission during BrainHack!",
    "chatchannel": "neurolibre",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/33",
    "issue_number": 33
  },
  {
    "title": "Pydra - updating tutorials",
    "goals": "We would like to update and improve Pydra tutorials, including instructions on how to move Nipype interface to Pydra.\nJoin us also if you just want to learn about the Pydra project and how to move your interface or workflow from Nipype to Pydra.",
    "link": "https://github.com/nipype/pydra",
    "website-image": "https://raw.githubusercontent.com/nipype/pydra/master/docs/logo/pydra_logo.jpg",
    "project-leads": "Dorota Jarecka, github: @djarecka, discord @dorota (coming on Thursday)\nGhislain Vaillant, github @ghisvail\nChris Markiewicz, github: @effigies",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Python if you want to work on the code or tutorial\nNo skills if you just want to run the tutorial",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "pydra",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/32",
    "issue_number": 32
  },
  {
    "title": "Sulci Lab: A collaborative tool for sulcal graph labelling",
    "goals": "SulciLab is a web based tool to visualize and manually labellize sulcal graph generated by BrainVISA/Morphologist.\nIt allows users to create select which graph to visualize, create, copy and share new labelings.\nThe project is still under basic development and require some user feedback and lot of small bugs should be corrected.\nIt also include a 3D viewer that could be extracted or replaced to a dependency.",
    "link": "https://github.com/BastienCagna/sulcilab",
    "website-image": "https://drive.google.com/file/d/1CR0aaMDeAP844HfMT4hEO71Kh5LhDYV5/view?usp=sharing",
    "project-leads": "Bastien Cagna (BastienCgn#0797)",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Brain Anatomy\nPython (Django)\nTypescript (React)",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)"
    ],
    "issues": "Feedback on installation\nReport any bug\nEnhance the UI or user experience",
    "twiter": "SulciLab is a web based tool to visualize and manually labellize sulcal graph generated by BrainVISA/Morphologist.",
    "chatchannel": "SulciLab-23",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/31",
    "issue_number": 31
  },
  {
    "title": "Mode-based morphometry (MBM)",
    "goals": "Classical approaches to studying neuroanatomy rely on statistical inferences at individual points (voxels or vertices), clusters of points, or a priori regions-of-interest (ROIs) and thus, they are restricted to a single spatial resolution scale. We develop an approach, called mode-based morphometry (MBM), that can be used to describe any empirical map of anatomical variations in terms of the fundamental, resonant modes\u2013\u2013eigenmodes\u2013\u2013of brain anatomy. This approach naturally yields a multiscale characterization of the empirical map, affording new opportunities for investigating the spatial frequency content of neuroanatomical variability.\nWe have developed a toolbox for this approach in Matlab. Depending on the expertise of participants, our goals for BrainHack are to make the toolbox more user-friendly, add more features, and translate it to Python.",
    "link": "https://github.com/NSBLab/MBM",
    "website-image": null,
    "project-leads": "Name: Trang Cao\nGitHub: https://github.com/NSBLab\nDiscord: trangcao.",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Coding skills\nThey will be tasks for different skills ranging from just starting coding on Matlab, wanting to try GUI on Matlab, to Premier League. Pythoneers are also welcomed.\nNon-coding skills\nIt is not all about coding! Are you someone with a good flair for good visualization? Someone with more experience who can make a good user interface? Someone who knows how to develop good, tidy and clear documentation?",
    "tutorials": [],
    "issues": null,
    "twiter": null,
    "chatchannel": "MBM",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/30",
    "issue_number": 30
  },
  {
    "title": "Enable subject level cohort search across BIDS datasets",
    "goals": "[Neurobagel\u2019s](https://www.neurobagel.org/) goal is to make it easy for researchers to annotate their own BIDS data with standardized terms and to provide solutions to make these harmonized metadata searchable.\nAs a proof of concept, we have done this for a large part of the OpenNeuro MRI data and put them here: https://github.com/OpenNeuroDatasets-JSONLD. The metadata can be searched here: https://query.neurobagel.org/\nWe are going to work on two projects for folks at any level of experience. Our goals are:\n- **Understand better how users want to interact with our tools**. Sit down with us, try the query tool or our \"Getting started\" documentation, and tell us what is easy and what can be improved. We specifically want to hear from people who are interested in a cross-dataset cohort search about how they would like to use Neurobagel in the future.\n- **Increase alignment with the BIDS community**. Neurobagel annotations are currently stored inside BIDS `participant.json` files [with additional json keys](https://github.com/OpenNeuroDatasets-JSONLD/ds004393/blob/e2117828736d09df96e911a1b4327f5f21afe7a6/participants.json#L26-L42). We would like to discuss how we can create these files in a way that makes them maximally useful to people in the wider BIDS ecosystem, and hopefully eventually fully BIDS compatible.\n- **Collaborate on automating the processing of OpenNeuro annotations**. We would like to have an automatic process that can be triggered (e.g. via some Github Action or hook) to pull a BIDS datalad dataset and run the Neurobagel metadata extractor to create a linked data view of the BIDS dataset that we can search over. All of the steps are already in place but done manually at the moment. We hope to find ways to automate this via Github or a different CI.",
    "link": "https://github.com/neurobagel",
    "website-image": null,
    "project-leads": "| Who             | Where      | Github     | Discord |\n|-----------------|------------|------------|---------|\n| Alyssa Dai      | In person  | @alyssadai | alyssadai#5780        |\n| Arman Jahanpour | On Discord | @rmanaem   | rmanaem        |\n| Sebastian Urchs | In person  | @surchs    | _surchs |",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "User feedback\n- everybody is welcome\n- having an interest in cross dataset cohort search or dealing with messy data\nDiscussing semantic annotation in BIDS\n- BIDS (beginner)\n- Experience working with messy (clinical) data\n- Research interest that wants to ask questions across several dataset\n- Interest in data harmonization and metadata\nAutomating processing of OpenNeuro metadata\n- Datalad\n- git, Github Actions, CI workflows in general\n- Python\n- Docker (nice to have)",
    "tutorials": [
      "[BIDS](https://school-brainhack.github.io/modules/bids/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)",
      "[VCS: Data management with Datalad](https://school-brainhack.github.io/modules/datalad/)",
      "[Virtualization](https://school-brainhack.github.io/modules/containers/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "neurobagel",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/29",
    "issue_number": 29
  },
  {
    "title": "dmri-nipreps",
    "goals": "We plan to continue expanding the support for different modalities of NiPreps. Continuing on that line, we recently released MRIQC with beta support for dMRI data. dMRIPrep has long been in the works, and we expect to make progress on this front too. Finally, we may delve into the eddymotion project with the implementation of a Gaussian Process model for eddymotion, thereby enhancing the dMRIPrep preprocessing pipeline's capability to handle motion-related artifacts.\nTherefore, we are planning to act on the following lines, depending on the appetite and preferences of brain hackers\n- MRIQC\n- improving the reportlets of the visual reports, including color FA, anisotropic power map, and/or carpetplot.\n- eddymotion\n- developing new models for diffusion and PET data:\n- Gaussian Process model to allow comparison vs. FSL topup (this line is most likely to directly contribute to DIPY).\n- PET model (continuing with the work initiated in the 2022 hackathon at OHBM Glasgow)\n- dMRIPrep\n- pipeline, package and containers makeover\nhttps://github.com/nipreps/mriqc\nhttps://github.com/nipreps/eddymotion\nhttps://github.com/nipreps/dmriprep",
    "link": "https://github.com/nipreps",
    "website-image": null,
    "project-leads": "Ariel rokem (GitHub: @arokem, Discord: @arokem) and Teresa Gomez (Github: @teresamg)",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "While we encourage participants of all skill levels to join, a good understanding of Python is recommended to contribute to this project. Some knowledge of diffusion MRI would also be helpful.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "nipreps-dmri",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/28",
    "issue_number": 28
  },
  {
    "title": "Publishing Code in Aperture Neuro",
    "goals": "Aperture Neuro is a new journal **from** the OHBM community **for** the OHBM community.\nIn a new initiative, Aperture Neuro aims to expand the formats of submissions beyond traditional PDF papers found in conventional journals, by including code submissions.\nIn the dynamic field of neuroimaging, researchers derive new insights into the brain through the application and development of innovative software and analysis tools. While these insights can be described in conventional PDF papers, many other aspects of researchers' work often do not go through a similar publication procedure, lacking peer review and full citability. These research outputs, collectively known as _research objects_, hold significant value for the neuroimaging community.\nExamples of such research objects include:\n- Code\n- Code wrappers\n- Pipelines\n- Toolboxes\n- Toolbox plugins\n- Code notebooks\nAlthough these research objects are typically not subject to peer review and are not indexed in standardized publication systems, they deserve to be citable in a manner that recognizes the author's contribution and aids in the assessment of their scholarly impact, such as their h-index.\nIn a special initiative, Aperture Neuro wants to invite members of the neuroimaging community to submit their research objects in the form of code.\nThis invitation is specifically aimed to code that fulfills the following criteria:\n- High quality\n- Open\n- Useful to the community\n- Not previously published as a peer-review paper\nThe goal of this hackathon project is to:\n- [ ] Identify codes that are used in the field of neuroimaging but are not citable via PubMed listed publications.\n- [ ] Build a database of code repositories that are widely used. This list of code could be given to the Aperture Editorial Board to invite authors for submissions.\n- [ ] Have a discussion on whether the submission guidelines from Aperture Neuro need to be revised to incorporate these codes.\nResources:\n- Journal website: [https://apertureneuro.org/ ](https://apertureneuro.org/)\n- Flyer [(pdf)]( https://drive.google.com/file/d/1Vml5T0-hDc0BWOhC3mcIGhn3fd_0jRpE/view?usp=sharing  )\n- Draft of call for papers with [submission guidelines](https://docs.google.com/document/d/16GQ56qXKGc0u86Fg8h7cDQq8x5J0lkz6dixonla4gIE/edit?usp=sharing )\n- [Table that is aimed to be extended. ](https://docs.google.com/spreadsheets/d/1eeWxKzl-dCffbMSaciWRC-0wPJwVAD2MtceT7hqEXr0/edit?usp=sharing)\nThis project is lead via online-attendees.",
    "link": "https://docs.google.com/spreadsheets/d/1eeWxKzl-dCffbMSaciWRC-0wPJwVAD2MtceT7hqEXr0/edit?usp=sharing",
    "website-image": "https://drive.google.com/file/d/1VQR-Mo1lXrSJIXVLQVGSM0dP9SgaOchj/view?usp=sharing",
    "project-leads": "Discord handle: renzohuber Twitter @layerfmri",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "No specific skills required",
    "tutorials": [],
    "issues": "Go through the methods section of the last few papers that you have been reading and see if all the code that has been used is cited with a PubMed listed reference.\nIf there is code that looks relevant to a wider community and is only referring to github, add it to the list of valuable code.",
    "twiter": "Community discussions on publishing code in the OHBM journal Aperture.\nThere is lots of good code out there that is waiting to be peer-reviewed and published. Let's identify it and make it citable.\n@ApertureOHBM\n#OHBMHackathon #Brainhack #OHBM2023",
    "chatchannel": "Code-Aperture",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/27",
    "issue_number": 27
  },
  {
    "title": "CiftiPy",
    "goals": "`cifti` is a neuroimaging file format that flexibly stores vertex and voxel data in the same file. It's the format of choice in the HCP processing pipelines for storing surface maps, but can also be used for cortical parcellations, brain segmentations, structural and functional connectomes, and many other applications.\nCurrently, there isn't an easy way to handle this format in python. Nibabel has support, but the interface is unintuitive and bulky.\nCiftiPy will be a wrapper around nibabel offering a convenient, numpy-based interface for accessing and manipulating cifti files. It will offer convenient methods for indexing cifti files by data-type, structure, and hemisphere, be easily and transparently viewed in an REPL (like pandas or xarray), and offer methods for common tasks.\n## Goals\nNo code has been written yet, but we have a fairly clear plan for the API. The goal will be to implement, test, and document the core interfaces.\n## Long term\nWe are prioritizing robustness over number of features, so we're purposefully trying to keep the scope as small as possible. If we get a good cifti interface built, however, it could in principle be extended to support other neuroimaging file types (gifti, nifti), resulting in a generalized, user-friendly nibabel wrapper.",
    "link": "https://github.com/pvandyken/ciftipy",
    "website-image": null,
    "project-leads": "Peter Van Dyken - pvandyken#9542\nMohamed Yousif - dunnom8#1502\nMauricio Cespedes Tenorio - mau_cespedes99#7386",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "(Any and none of these skills are welcome! This is more a list of what tech we'll use)\n- Python\n- git\n- Documentation (Sphinx, readthedocs, markdown)\n- Cifti files (read the spec [here](https://www.nitrc.org/forum/attachment.php?attachid=341&group_id=454&forum_id=1955)\n- [nibabel](https://nipy.org/nibabel/)\n- Numpy\n- Python testing (pytest, [hypothesis](https://hypothesis.readthedocs.io/en/latest/index.html))\n- Github actions",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[A introduction to Bash](https://school-brainhack.github.io/modules/introduction_to_terminal/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": "ciftipy makes it easy to view, index, and manipulate cifti files with python",
    "chatchannel": "ciftipy",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/26",
    "issue_number": 26
  },
  {
    "title": "Post-fMRIPrep ICA-AROMA BIDS-App",
    "goals": "The aim of this hackathon project is to create an ICA-AROMA post-fMRIPrep pipeline. fMRIPrep is a robust and user-friendly preprocessing tool for diverse fMRI data. ICA-AROMA, on the other hand, is a data-driven method that automatically identifies and removes motion-related independent components from fMRI data.\nPrior to fMRIPrep 23.1, ICA-AROMA was an optional component of fMRIPrep, but it was removed as being out-of-scope, as it can be performed on fMRIPrep outputs.\nThe project focuses on creating an ICA-AROMA pipeline that accepts fMRIPrep outputs as its inputs, in particular MNI152NLin6Asym-resampled BOLD series. The pipeline will apply SUSAN smoothing, run MELODIC, and finally ICA-AROMA. The pipeline will provide options for users to select specific outputs, including noise components and non-aggressively denoised BOLD series, as well as generate reports.\nTo join the discussion and contribute to this project, you can find more information in the related issue at [nipreps/fmriprep#2936](https://github.com/nipreps/fmriprep/issues/2936).",
    "link": "https://github.com/nipreps/fmripost-aroma",
    "website-image": null,
    "project-leads": "C\u00e9line Provins, GitHub: @celprov , discord: cprovins",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Having basic Python knowledge is important, however all levels of experience are welcome.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[BIDS](https://school-brainhack.github.io/modules/bids/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "fmriprep_aroma",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/25",
    "issue_number": 25
  },
  {
    "title": "Reporting FreeSurfer outcomes with NiReports",
    "goals": "This project aims to gather the output of FreeSurfer in comprehensive reports. Using the powerful NiReports tooling, reportlets will be created from FreeSurfer runs to visualize and assess the quality of neuroimaging processing steps.\nThe project will leverage the NiReports assembler, which utilizes PyBIDS, to collect the reportlets generated by FreeSurfer. The assembler follows a report specification in YAML format, specifying the query for specific reportlets, their associated metadata, and text annotations. Ultimately, the assembler combines the reportlets into a single HTML file, providing an informative and concise summary of the FreeSurfer analysis.\nFreeSurfer is a widely used software package for structural and functional neuroimaging analysis, while NiReports, a part of the NiPreps' reporting and visualization tools, offers a powerful framework for organizing and presenting the results. This hackathon project aims to streamline the reporting process and enhance the visualization of FreeSurfer output, facilitating the interpretation and analysis of neuroimaging data.",
    "link": "https://github.com/nipreps/nireports",
    "website-image": null,
    "project-leads": "Michael Dayan, GitHub: @neurorepro , discord:",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "To make the most of this hackathon project, having some Python knowledge is important. While prior experience with FreeSurfer and NiReports is appreciated, it's not a requirement. We encourage you to join us and contribute your skills, regardless of your level of expertise.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "nireports_freesurfer",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/24",
    "issue_number": 24
  },
  {
    "title": "fMRIPrep-integrate AFNI left and right flip detection tool into fMRIPrep",
    "goals": "In this hackathon project, we aim to enhance the fMRIPrep pipeline by integrating AFNI's left and right flip detection feature. This tool detects potential left-right flips between subject EPIs and anatomicals, ensuring accurate alignment and analysis of neuroimaging data.",
    "link": "https://www.frontiersin.org/articles/10.3389/fninf.2020.00018/full",
    "website-image": null,
    "project-leads": "C\u00e9line Provins, GitHub: @celprov , discord:  cprovins",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Having basic Python knowledge is important, however all levels of experience are welcome. Familiarity with building a workflow using Nipype is a plus but is not required.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "fmriprep_qa_xyflip",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/23",
    "issue_number": 23
  },
  {
    "title": "EyeTracker to BIDS",
    "goals": "This project aims to encode eye-tracker data into BIDS, perhaps including it as a new feature of the phys2bids Python library. phys2bids is a powerful library designed to format physiological files in BIDS.\nBy leveraging phys2bids and integrating eye-tracker data into BIDS, we will establish a standardized approach for organizing and sharing eye-tracking data obtained in neuroimaging experiments. BIDS provides a simple and widely adopted framework for structuring neuroimaging and behavioral data, saving valuable time spent on data rearrangement or script modification.\nPython knowledge is recommended but optional to participate in this hackathon project. Whether you're an experienced Python developer or just starting, your contribution is valuable.",
    "link": "https://github.com/nipreps/",
    "website-image": null,
    "project-leads": "Elodie Savary, GitHub: @esavary, discord: esavary",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Python knowledge is recommended for this hackathon project. All levels of experience are welcome, whether you're an experienced Python developer or just starting out.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "et2bids",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/22",
    "issue_number": 22
  },
  {
    "title": "Migas Analytics: create additional visualizations",
    "goals": "Migas is a telemetry web service that collects, aggregates, and displays software usage. It is broken up into two parts, a client and server. We would like to expand the types and quality of the visualizations, providing authenticated users a dynamic and clearer view of their projects\u2019 usage.",
    "link": "https://github.com/nipreps/migas-server",
    "website-image": null,
    "project-leads": "Mathias Goncalves, GitHub: @mxgd, discord:",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "While we encourage participants of all skill levels to join, a good understanding of Python is recommended to contribute to this project.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "migas_viz",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/21",
    "issue_number": 21
  },
  {
    "title": "fMRIPrep-Split into separate fit & apply workflows",
    "goals": "fMRIPrep is a large, computationally intensive workflow that can potentially produce an order of magnitude more data than is input. However, many of these derivatives can be deterministically generated by a fairly small subset of \"first order\" derivatives, such as registration transforms.\nThis project aims to create a workflow that generates the minimal set of derivatives, as well as workflows for generating reports and other derivatives, such as resampled BOLD series and confound time series. The desired end result is a collection of modular workflows that can be composed either to produce the minimal set of derivatives or the full set that are the current outputs of fMRIPrep.",
    "link": "https://github.com/nipreps/fmriprep/",
    "website-image": null,
    "project-leads": "Chris Markiewicz, GitHub: @effigies, discord: Chris Markiewicz (gh: effigies)",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "While we encourage participants of all skill levels to join, a good understanding of Python is recommended to contribute to this project.",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "fmriprep_fit_apply",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/20",
    "issue_number": 20
  },
  {
    "title": "Nobrainer: A framework for developing neural network models for 3D image processing",
    "goals": "Nobrainer-zoo is a toolbox with a collection of deep learning neuroimaging models that eases the use of pre-trained models for various applications. Nobrainer-zoo provides the required environment with all the dependencies for training/inference of models.\nDuring the hackathon, we aim to incorporate new models into the zoo along the lines of existing ones. Some of the models include TopoFit, CorticalFlow, Vox2Cortex, CortexODE, PialNN, and many other deep learning-based neuroimaging models that users would want to see as part of the nobrainer-zoo.\nTasks are designed to be really simple and to facilitate this model integration, we also provide a step-by-step documentation/guide that can be found at https://github.com/neuronets/trained-models/blob/master/add_model_instructions.md",
    "link": "https://github.com/neuronets/nobrainer-zoo.git",
    "website-image": null,
    "project-leads": "@satra",
    "hub": "Montreal",
    "otherhub": [
      "Americas"
    ],
    "skills": "Python, Datalad, Docker, Singularity",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[VCS: Data management with Datalad](https://school-brainhack.github.io/modules/datalad/)"
    ],
    "issues": "https://github.com/neuronets/trained-models/issues/51",
    "twiter": null,
    "chatchannel": "nobrainer-project",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/19",
    "issue_number": 19
  },
  {
    "title": "Physiopy - Semi-Automated Workflows for Physiological Signals",
    "goals": "Physiopy is a community formed around developing solutions to acquire, process, and utilize physiological files in neuroimaging contexts. Physiopy is developing or has developed several physiology-oriented modular toolboxes to this end, including 1) _phys2bids_, a toolbox to standardize physiological files in BIDS format 2) _peakdet_, a toolbox for automatic detection and manual correction of  peaks in physiological data and 3) _phys2denoise_, a toolbox to prepare derivatives of physiological data for use in fMRI denoising. Currently, we have no complete workflows encompassing all steps of physiological data processing and model estimations. **The goal of this project is to facilitate a unified workflow across these toolboxes for semi-automated physiological signal processing.**\nDuring this hackathon, we aim to:\n- Create a semi-automated workflow based on peakdet and phys2denoise to process respiratory and cardiac signals and obtain models of physiological signal variance for neuroimaging analysis (e.g. RVT, HRV, ...)\n- Create a command line interface (CLI) for the workflows\n- Update and upgrade the current codebase of peakdet and phys2denoise, including better harmonization between toolboxes\nExtra and optional aims could include:\n- Create a graphical report of the workflows output\n- BIDS-App-lify the workflows: we want to create an entry point to transform the workflow into a [BIDS Application](https://bids-apps.neuroimaging.io/)\n- Pydra-ify the libraries: to learn the strength of Pydra as a workflow manager, we can create a version of the workflow using Pydra.\n- Add support for eye-tracking and skin conductance data\nAll contributions are welcome and accepted, from any level of contribution. We follow the[ all-contributors specification](https://allcontributors.org/docs/en/emoji-key) to report contributions, and adopt physiopy's [contributors guide](https://physiopy.github.io/community/contributor-guide/) and [code of conduct](https://physiopy.github.io/community/CODE_OF_CONDUCT/).",
    "link": "https://github.com/physiopy/",
    "website-image": "https://raw.githubusercontent.com/physiopy/phys2bids/master/docs/_static/physiopy_logo_small.png",
    "project-leads": "Mary Miedema (Montreal), Github Username: m-miedema , Discord Username: m-miedema\nRoza Gunes Bayrak (Americas), Github Username: rgbayrak  Discord Username: @rgbayrak,\nMarie-Eve Picard (Montreal), Github Username: me-pic, Discord Username: Marie-Eve Picard (she/her)#4750",
    "hub": "Montreal",
    "otherhub": [
      "Americas"
    ],
    "skills": "We welcome all contributors and contributions, from any skill set and level. Prior work with physiological data would be useful \u2013 we\u2019d like to compare how different labs are processing their data. However, we are big believers in learning-by-doing!\nNo prior git knowledge necessary, if willing to learn on the spot!\nLikewise, basic knowledge of python and toolbox set up are helpful, but not necessary.\nHowever, if you are acquainted with bokeh or html reports or pygui or other graphic interfaces, we are looking for you!!!",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)",
      "[Virtualization](https://school-brainhack.github.io/modules/containers/)"
    ],
    "issues": "- Add import support for BIDS-format physiological data\n- Lay out a sample workflow to process physiological data\n- Write documentation about the workflow\n- Write a tutorial on the workflow-",
    "twiter": "Physiopy - semi-automated workflows for physiological signals\nhttps://github.com/physiopy/\n@MaryMiedema @redgreenblues @stemoia\n#OHBMHackathon #Brainhack #OHBM2023 #physiopy",
    "chatchannel": "physiopy-workflows",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/18",
    "issue_number": 18
  },
  {
    "title": "Bring [HeuDiConv](https://github.com/nipy/heudiconv) to the next level!",
    "goals": "I plan to contribute by working on the Heudiconv tool, an essential utility in the neuroimaging community that converts DICOM datasets to BIDS (Brain Imaging Data Structure) format.\nGoals:\n- **Enhancement of Heudiconv tool**: The primary goal is to address various existing enhancement requests for the Heudiconv tool. By refining the tool's functionality, we can streamline the conversion process and improve the usability of Heudiconv for researchers around the world.\n- Might also include enhancement of BIDS tools to e.g. provide helpers to rename/delete BIDS files etc.\n- **Collaboration and knowledge exchange**: Collaborating with others to improve Heudiconv will foster a productive exchange of ideas and knowledge. The aim is to learn from others while contributing to the community's growth and development.\n- **Improving documentation**: A well-documented tool is an easily accessible tool. By focusing on improving Heudiconv's documentation, the goal is to make the tool more approachable and useful to both new and existing users.\n- **Increasing community engagement**: The project aims to engage more members of the neuroimaging community with the Heudiconv tool. By working on enhancements, we can encourage more researchers to use and contribute to the tool in the future.",
    "link": "https://github.com/nipy/heudiconv",
    "website-image": "https://avatars.githubusercontent.com/u/233707?s=48&v=4",
    "project-leads": "Yaroslav O. Halchenko @yarikoptic",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Python\nHaving experience with DICOM to BIDS conversion would be a plus",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[BIDS](https://school-brainhack.github.io/modules/bids/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)",
      "[VCS: Data management with Datalad](https://school-brainhack.github.io/modules/datalad/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "heudiconv",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/17",
    "issue_number": 17
  },
  {
    "title": "PhysioQC: A physiological data Quality Control toolbox with physiopy",
    "goals": "Physiopy is a community formed around developing solutions to operate physiological files in neuroimaging setups. We manage a few physiology-oriented toolboxes to process physiological data, and we would like to add a new toolbox to help quality assurance of physiological data through (automatised) quality control. If you are familiar with MRIQC, or afni proc quality control - we want to do something similar, but for physiological data.\nDuring previous hackathons and meetings we planned the toolbox, and during these upcoming three days we'll implement a workflow to automatise it and get textual and image-based outputs, in order to get a starting point to report valuable QC information.\nAll contributions are welcome and accepted, from any level of contribution. We follow the [all-contributors specification](https://allcontributors.org/docs/en/emoji-key) to report contributions, and adopt physiopy's [contributors guide](https://physiopy.github.io/community/contributor-guide/) and [code of conduct](https://physiopy.github.io/community/CODE_OF_CONDUCT/).",
    "link": "https://github.com/physiopy/physioqc",
    "website-image": "https://github.com/physiopy/phys2bids/blob/master/docs/_static/physiopy_logo_1280x640.png?raw=true",
    "project-leads": "Stefano Moia, Github Username: smoia, Discord Username: smoia",
    "hub": "Montreal",
    "otherhub": [
      "Europe / Middle East / Africa"
    ],
    "skills": "We welcome all contributors and contributions, from any skillset and level.\nWe are big believers in learning-by-doing!\nNo prior git knowledge necessary, if willing to learn on the spot!\nBasic knowledge of python, toolbox set up, and/or signal processing are helpful, but not necessary.",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": "- Write simple functions to compute basic signal properties\n- Select data to test the library",
    "twiter": "PhysioQC: A physiological data Quality Control toolbox with physiopy @stemoia\n#OHBMHackathon #Brainhack #OHBM2023 #Physiopy",
    "chatchannel": "physiopy-qc",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/16",
    "issue_number": 16
  },
  {
    "title": "Improving surface functionality in Nilearn",
    "goals": "## INTRODUCTION\nNilearn is an open-source Python package for fast and easy analysis and visualization of brain images. It provides statistical and machine-learning tools, with instructive documentation and a friendly community. It includes applications such as multi-voxel pattern analysis (MVPA), decoding, predictive modelling, functional connectivity, and brain parcellations. In recent years, we have developed functionality to support working with surfaces and we now have concrete plans for extending surface support in Nilearn in order to extend this functionality. To this end, we aim to get contributors to get familiar with the existing surface functionality and to work on issues to improve the surface module and surface plotting functions.\n## GOALS FOR THE BRAIN HACK\nContributors are encouraged to work on issues in the project board by opening pull requests. These include good first issues that will help first time contributors get started and also issues relating to surface functionality. Contributors are also welcome to open issues for relevant bugs or suggestions for enhancement of the current surface functionality.",
    "link": "https://github.com/nilearn/nilearn",
    "website-image": "https://nilearn.github.io/stable/_static/nilearn-transparent.png",
    "project-leads": "Hao-Ting Wang, Github: @htwangtw, Discord: haodareyou\nRemi Gau, Github: @Remi-Gau, Discord: remigau\nYasmin Mzayek, Github: @ymzayek, Discord: ymzayek\nElizabeth DuPre, Github: @emdupre, Discord: emdupre#8727",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "We welcome all contributions from various skill sets and levels. This can include opening discussions around improvements to the documenation and/or code base, answering or commenting on questions or issues raised on github and [neurostars](https://neurostars.org/tag/nilearn), reviewing pull requests, and [contributing code](https://nilearn.github.io/stable/development.html#how-to-contribute-to-nilearn).",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[Machine learning basics](https://school-brainhack.github.io/modules/machine_learning_basics/)",
      "[Machine learning for neuroimaging](https://school-brainhack.github.io/modules/machine_learning_neuroimaging/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": "#### Surface project issues\nCentralized on this kanban board: https://github.com/orgs/nilearn/projects/6\n#### Other small issues to open your first pull request\n- [update contributors affiliation](https://github.com/nilearn/nilearn/issues/3808)\n- [stop checking versions of some old dependencies](https://github.com/nilearn/nilearn/issues/3793)\n- [refactor some tests to use context managers](https://github.com/nilearn/nilearn/issues/3796)\n- [nilearn fun facts](https://github.com/nilearn/nilearn/issues/3791)",
    "twiter": "Get familiar with nilearn's surface data functionality and help us improve it! https://nilearn.github.io/stable/index.html",
    "chatchannel": "nilearn_surface",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/15",
    "issue_number": 15
  },
  {
    "title": "Neuroimaging Meta-Analyses! (NiMARE + Neurosynth-Compose)",
    "goals": "We are on an exciting precipice of making reproducible/sharable neuroimaging meta-analyses more accessible to a broader audience and we want your help to make it a reality.\nWe have multiple projects you can interface with that fit your level of experience (from newcomer to veteran)\n# Novice Projects\n## User testing\nWalk through our https://compose.neurosynth.org/ using a [tutorial](https://neurostuff.github.io/meta-analysis-book).\n### Goals\nprovide feedback on what was intuitive/what didn\u2019t make sense/what didn\u2019t work in the tutorial or on the platform.\n# Intermediate Projects\n## Coordinate Based Meta-Regression exploration\nIf you have run a meta-analysis before using kernel-based methods and want to try Coordinate-based meta-regression\n### Goals\n- Execute a meta-analysis with meta-regression and compare the results to a kernel-based method\n- Provide feedback on the usability of the library\n- Identify bugs\n## Documentation/Educational Material Development\nIf you have some knowledge of meta-analyses and want to explain concepts and help organize an educational book, we can use contributors to the meta-analysis-book\n### Goals\n- Create exercises for sections of the book\n- Provide more fundamental knowledge about kernel-based methods\n- Outline Image-Based Meta-Analysis Section\n# Advanced Projects\n## Data mining\nUse the neurosynth dataset to recreate term meta-analyses using coordinate-based meta-regression.\n### Goals\n- Determine the feasibility of using neurosynth dataset with CBMR\n- Compare results with original term meta-analyses on neurosynth\n## Image-Based Meta-Analysis\nPrototype workflow for Image Based Meta-Analysis, and help develop the components to make it possible to run an image-based meta-analysis on compose.neurosynth.org and NiMARE\n### Goals\n- Create a workflow to complete an Image Based Meta-Analysis\n## Support Coordinate Based Meta-Regression on Neurosynth Compose\nhttps://compose.neurosynth.org/\nHelp make a new neuroimaging meta-analytic method accessible to a broader audience\n### Goals\n- Outline changes to the API\n- Outline changes to the meta-analysis runner\n- Create a coordinate-based meta-regression workflow on neurosynth-compose",
    "link": "https://github.com/neurostuff/NiMARE",
    "website-image": "https://compose.neurosynth.org/static/synth.png",
    "project-leads": "| Name                 | github    | discord         |\n|----------------------|-----------|-----------------|\n| James Kent           | jdkent    | jdkent          |\n| Alejandro De La Vega | adelavega | neurozorro#2158 |\n| Yifan Yu             | yifan0330 | Yifan Yu#0260   |",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Novice Projects:\n- None\nIntermediate Projects:\n- Python (beginner/confirmed)\n- meta-analyses (confirmed)\n- git: 0/1\nAdvanced Projects:\n- Python (confirmed/advanced)\n- meta-analyses (confirmed)\n- git: 1/2",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)",
      "[VCS: Data management with Datalad](https://school-brainhack.github.io/modules/datalad/)"
    ],
    "issues": null,
    "twiter": "Hack with us on neurosynth-compose and NiMARE to create reproducible/sharable neuroimaging meta-analyses!",
    "chatchannel": "neurosynth-compose",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/14",
    "issue_number": 14
  },
  {
    "title": "Clinica's image processing pipeline QC",
    "goals": "The goal is to establish a QC protocol that includes both metric and visual-based assessment, for the various image processing pipelines available in Clinica.\nThe project would be planned would be as follows:\n- First, a round table to discuss the different practices of the participants, on which pipelines participants will be working on, as well as the objectives for the end of the hackathon. Before the end of the round table, two work groups should be established: one working on image quality metrics (IQMs), and the second working on visual QC\n- Next, we expect the two groups to work independently:\n- The IQM group will select some metrics that feel relevant, and evaluate them.\n- The visual QC group will set-up a few different visual QC proposal (i.e. views) for each pipeline they're studying, and attempt to evaluate their effectiveness\nWe expect the outcomes of this hackathon to be a set of IQM candidates and of graphical representation that could be included in the QC tools of Clinica",
    "link": "https://github.com/aramis-lab/clinica",
    "website-image": "https://www.clinica.run/assets/images/clinica-icon-257x257.png",
    "project-leads": "Name: Matthieu Joulot\nGitHub: MatthieuJoulot\nDiscord: Matthieu Joulot",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "The skills we are looking for are:\n- expertise in visual QC of neuro-imaging (structural MRI, diffusion MRI, PET) processing (segmentation, registration, ...)\n- expertise in the use of IQMs for quantitative QC of neuro-imaging (structural MRI, diffusion MRI, PET) processing (segmentation, registration, ...)",
    "tutorials": [
      "[BIDS](https://school-brainhack.github.io/modules/bids/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "processing-qc",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/13",
    "issue_number": 13
  },
  {
    "title": "Physiopy - Documentation of Physiological Signal Acquisition Community Practices",
    "goals": "Physiopy is a community formed around developing solutions  to operate physiological files in neuroimaging setups. Physiopy meetings feature discussions on what are suggested practices to set up and work with physiological data, that we are compiling to become available documentation for all interested users. This project specifically will work on continuing the compilation of such documentation, including a detailed overview of what physiological data are typically recorded during an fMRI experiment, how these signals are recorded, and how these signals can improve our modeling of fMRI time series data. We also hope to expand our package documentation containing tips and strategies on how to collect various forms of physiological data and the use of our packages. Imaging cerebral physiology as either signals of interest or denoising, is an active field of research, and we hope to encourage all users to get the latest recommendations prior to initiating a new study.\nThis project does not necessarily require coding skills to join. If you want to take your first step with git/GitHub and documentation, we\u2019re happy to have you on board!",
    "link": "https://github.com/physiopy/physiopy.github.io",
    "website-image": "https://github.com/physiopy/phys2bids/blob/master/docs/_static/physiopy_logo_1280x640.png?raw=true",
    "project-leads": "Sarah Goodale, Github Username: goodalse2019 , Discord Username: sarah goodale#5094\nInes Esteves, Github Username: isesteves, Discord Username: _iesteves\nStefano Moia, Github Username: smoia, Discord Username: smoia",
    "hub": "Montreal",
    "otherhub": [
      "Europe / Middle East / Africa"
    ],
    "skills": "Excitement for learning the best practices in physiological signal acquisition. We welcome all contributions from any skill set and level, this project will predominantly be focused on documentation contributions. No prior knowledge on physiological data necessary!\nGit - we welcome any level of git (0-3), markdown knowledge helpful",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": "Improve documentation for package\nBuild best practices libraries and summaries for various physiological signals (e.g., respiratory, cardiac, skin conductance, etc.)\nCheck open source libraries and software similar to what we do\nBuild list of open source datasets with physiological signals",
    "twiter": "Physiopy - documentation of physiological signal acquisition and best practices\nphysiopy/physiopy.github.io\n@s_goodale23 @isesteves @joanacspinto @stemoia\n#OHBMHackathon #Brainhack #OHBM2023",
    "chatchannel": "physiopy-documentation",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/12",
    "issue_number": 12
  },
  {
    "title": "NARPS Open Pipelines",
    "goals": "The goal of the NARPS Open Pipelines project is to create a codebase reproducing the 70 pipelines of the NARPS project (Botvinik-Nezer et al., 2020) and share this as an open resource for the community.\nIn particular, we would like to focus on these tasks during the Brainhack:\n* Start reproducing new pipelines, based on the knowledges of participants (i.e.: which fMRI analysis software they are used to, whether they use Python or not, ...) ;\n* Improving documentation and accessibility of the project.",
    "link": "https://github.com/Inria-Empenn/narps_open_pipelines",
    "website-image": "https://raw.githubusercontent.com/Inria-Empenn/narps_open_pipelines/main/assets/images/project_illustration.png",
    "project-leads": "Boris Cl\u00e9net (https://github.com/bclenet) - virtual hub Europe\nCamille Maumet (https://github.com/cmaumet) - Montreal\nElodie Germani  (https://github.com/elodiegermani) - Montreal",
    "hub": "Europe / Middle East / Africa",
    "otherhub": [
      "Montreal"
    ],
    "skills": "- Base knowledge of git and GitHub\n- Able to understand Python code\n- Understanding of fMRI analysis pipelines\n- Ideally but not required : some Nipype knowledge\n- Ideally but not required : having used SPM or FSL or AFNI or nistats",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": "* [Debug pre-implemented pipelines](https://github.com/Inria-Empenn/narps_open_pipelines/issues/3)\n* Write the pseudo-code for a pipeline\n* Documentation : write a nice summary of NARPS",
    "twiter": "NARPS Open Pipelines\nhttps://github.com/Inria-Empenn/narps_open_pipelines\nProject leader: Boris Cl\u00e9net with @cmaumet @elodieGermani\n#OHBMHackathon #Brainhack #OHBM2022",
    "chatchannel": "narps-open",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/11",
    "issue_number": 11
  },
  {
    "title": "K-particles (a.k.a. what would happen to brains if we explode k-space?)",
    "goals": "## Description\nJoin us on an extraordinary visual adventure as we dive deep into the captivating realm of K-Space. Through the power of particle ~explosions~ animations, our project aims to shed light on the hidden wonders of magnetic resonance imaging (MRI) by explo~d~ring the intricacies of k-space and its relationship to the Fourier transform and brain images. Our ultimate goal is to create an enchanting video that unveils the magic of k-space sampling patterns and sparks curiosity among viewers.\nThe primary objective of this project is to leverage particle animations to provide insights into the journey of traveling and sampling the k-space. By generating captivating visualizations, we aim to demystify the concept of k-space and the role it plays in MRI, engaging both the scientific community and the general public in a delightful exploration of this fundamental aspect of imaging.\n## Goals\n- _Particle Animation Wizardry:_ We will create an array of animated particles that represent the journey within the k-space. These particles will travel, interact, and dynamically respond to the sampling process, offering a visually captivating representation of the Fourier transform in action.\n- _K-Space ~Explosion~ Sampling Patterns:_ Through manipulation of the animated particles, we will generate various k-space sampling patterns that demonstrate the importance of sampling strategies in MRI. By altering particle behavior, density, and distribution, we will illustrate the impact of different sampling schemes on image quality and resolution.\n- _Video Compilation:_ The generated particle animations and k-space sampling patterns will be compiled into a visually stunning and informative video. This video will showcase the beauty and complexity of the k-space journey, making it accessible to a wide audience. To reach a broad community of researchers and enthusiasts, we will publish the final video on YouTube. This platform will enable us to share the captivating visuals, educate viewers about k-space and the Fourier transform, and spark curiosity and discussions around the fascinating world of MRI.",
    "link": "TODO",
    "website-image": "https://drive.google.com/file/d/1r2lLUgqEoLL2gsW9ejSGrOvD6aOli3y0/view?usp=sharing",
    "project-leads": "Omer Faruk Gulban, Github: @ofgulban , Discord: ofgulban",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "- Python\n- ffmpeg",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[Python: Visualisation](https://school-brainhack.github.io/modules/python_visualization/)"
    ],
    "issues": "- Generate animations using the example scripts",
    "twiter": "TODO",
    "chatchannel": "k-particles",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/10",
    "issue_number": 10
  },
  {
    "title": "PHOTONAI",
    "goals": "## INTRODUCTION\nWith photonai, we have designed a machine learning software that abstracts and condenses machine learning analyses to the most important design decisions, so that it can be applied from practitioners in medicine and the Life Sciences. As a part of that, we have automated the nested cross-validation and hyperparameter optimization loop. However, the optimal approach for choosing the most suitable hyperparameter configuration continues to be an open problem. For example, the hyperparameter configuration that performs best on the validation set might be overly specific to the particularities of the validation set and thus underperform in new applications.\n## GOALS FOR THE BRAIN HACK\n- brainstorm strategies on how to select the best hyperparameter configuration to maximize generalization performance\n- implement ensembling techniques, i.e. select several hyperparameter configurations",
    "link": "github.com/wwu-mmll/photonai",
    "website-image": null,
    "project-leads": "Jan Ernsting, Github: jernsting, Discord: Jan#5471\nRamona Leenings, Github: rleenings, Discord: ramona_photonai",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Basic Python\nBasic Machine Learning or Statistic Knowledge",
    "tutorials": [
      "[Set up a brainhack friendly computing environment](https://school-brainhack.github.io/modules/installation/)",
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[Python: Data analysis with Python](https://school-brainhack.github.io/modules/python_data_analysis/)",
      "[Machine learning basics](https://school-brainhack.github.io/modules/machine_learning_basics/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": null,
    "chatchannel": "photonai",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/8",
    "issue_number": 8
  },
  {
    "title": "Cerebro: One tool to view them all",
    "goals": "Cerebero Viewer is a Pythonic 3D viewer to visualize and plot brains and neuroimaging data.\nIt's still in early development, so there's a lot that you could help with:\n- Contributing code: You could help implementing parts of Cerebro\n- Testing current development version: Reporting bugs is the first step to solving them!\n- Documentation: To help the experience better for future users\n- Ideas/suggestions: To have ideas on what's currently missing and what you'd like us to add next!",
    "link": "https://github.com/sina-mansour/Cerebro_Viewer",
    "website-image": "https://github.com/sina-mansour/Cerebro_Viewer/raw/main/static/images/screen.png?raw=true",
    "project-leads": "Sina Mansour L.\nGitHub: [sina-mansour](https://github.com/sina-mansour)\nDiscord: Sina_Mansour_L\nTwitter: @Sina_Mansour_L",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "The skills depend on the type of contribution,\nTo develop code, intermediate Python knowledge would be needed.\nTo test the code, beginner Python familiarity is enough.\nTo write documentation, no particular skill is required but familiarity with Markdown or potential documentation tools can be helpful.\nFinally, familiarity with git and GitHub would also be helpful.",
    "tutorials": [
      "[Python: Writing a script](https://school-brainhack.github.io/modules/python_scripts/)",
      "[VCS: Using Git and Github](https://school-brainhack.github.io/modules/git_github/)"
    ],
    "issues": null,
    "twiter": "\ud83e\udde0 Cerebero Viewer is a Python package that aims to become the visualization toolbox required for a neuroimager in an interactive yet scriptable format.\n\ud83c\udf1f Cerebero aims to extend the idea of reproducibility from scripts to of brain visualizations.",
    "chatchannel": "Cerebro",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/6",
    "issue_number": 6
  },
  {
    "title": "The BIDS connectivity project - current state and next steps of the BEPs",
    "goals": "Besides `BIDS`' success, expansion, and description of multiple data modalities, gaps still exist in developing the standard to effectively support the process of scientific results reporting. Among others, this prominently refers to data obtained through and during connectivity analyses. This comprises brain parcellations, connectivity maps, structural and functional connections, major white matter tracts, diffusion signal models, white matter tractograms and tractometry, as well as networks based on dimensionality reduction. Sharing processed data and features in addition to raw and minimally-processed data is critical to accelerating scientific discovery. This is because substantial effort, software, and hardware instrumentation, and know-how are required to bring raw data to a usable state. The aim of the present project is to extend the BIDS standard to encompass derivatives resulting from experiments related to macroscopic brain connectivity (U.S. National Institutes of Health NIMH R01-MH126699). During the Brainhack, we would like to\n1. Gather feedback from experts, users, tool developers, ie everyone!\n2. Work on the respective [BEPs](https://pestillilab.github.io/bids-connectivity/scope_approach/)\n3. Convert `BEP`s from `GoogleDocs` to `GitHub` `PR`s",
    "link": "https://pestillilab.github.io/bids-connectivity/",
    "website-image": "https://pestillilab.github.io/bids-connectivity/img/logo.svg",
    "project-leads": "Peer Herholz, GitHub: [peerherholz](https://github.com/peerherholz), discord: peerherholz\nFranco Pestilli, GitHub: [francopestilli](https://github.com/francopestilli), discord:\nAriel Rokem, GitHub: [arokem](https://github.com/arokem), discord",
    "hub": "Montreal",
    "otherhub": [],
    "skills": "Experience with one of our covered data modalities and respective analysis software packages would be helpful: `s/fMRI`, `dMRI`, `PET`, `MEG`, `i/EEG`. Additionally, knowledge of `BIDS` would come in handy.\nHowever, these are not requirements: we're happy to welcome everyone interested.",
    "tutorials": [],
    "issues": null,
    "twiter": "Interested in `Brain connectivity` and `FAIR data`? The [BIDS connectivity project](https://pestillilab.github.io/bids-connectivity/) might be of interest to you! During the Brainhack we will discuss work on the different connectivity-related `BIDS Extension Proposal`s (`BEP`s) and welcome support from all interested parties!",
    "chatchannel": "bids-connectivity",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/2",
    "issue_number": 2
  },
  {
    "title": "FSuB-Extractor",
    "goals": "- [ ] 1. Begin migration to Pydra or Nipype workflows\n- [ ] 2. Reorganize / Rename / BIDS-ify outputs\n- [ ] 3. Make a software container with dependencies\n- [ ] 4. Set up testing / continuous integration workflows on repository\n- [ ] 5. More beta testers!",
    "link": "https://github.com/smeisler/fsub_extractor",
    "website-image": null,
    "project-leads": "Steven Meisler (Americas / Montreal)\nhttps://github.com/smeisler\nDiscord Login: JazzyVibes#1404\n[smeisler@g.harvard.edu](mailto:smeisler@g.harvard.edu)",
    "hub": "Montreal",
    "otherhub": [
      "Americas"
    ],
    "skills": "Familiarity with one or multiple of:\n- Python\n- MRtrix\n- DIPY\n- CIFTI processing\n- FreeSurfer\n- Pydra or Nipype\n- CircleCI\n- Docker/Apptainer/Singularity containerization",
    "tutorials": [],
    "issues": "- Documentation\n- Beta testing / error reporting",
    "twiter": "Hi! The FSuB-Extractor is a tool that enables users to extract and analyze white matter bundles based on their intersection with gray matter functional ROIs. This approach has been used to study **f**unctional **su**b-components of **b**undles (FSuB) that support certain cognitive and perceptive tasks [(e.g., Kubota et al., 2022, _Cerebral Cortex_)](https://academic.oup.com/cercor/article-abstract/33/6/2485/6603928).\nRight now we have a functioning workflow, but we would like to formalize it more by migrating our workflow to something like Pydra or Nipype, and set up a software container and continuous integration workflow. We would also like to have outputs that follow BIDS as much as they can (keeping in mind the BIDS derivatives conventions -including connectivity derivatives- are still being codified). Even if you are unexperienced with contributing to code bases, we would still greatly appreciate feedback from beta testers!\nPlease contact me if you are interested or have questions!",
    "chatchannel": "fsub-extractor",
    "coc": [
      "I agree to follow the OHBM Code of Conduct during the hackathon"
    ],
    "issue_link": "https://github.com/ohbm/hackathon2023/issues/1",
    "issue_number": 1
  }
]